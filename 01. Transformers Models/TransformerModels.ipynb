{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ],
      "metadata": {
        "id": "s_rod7u5Z3Bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-c8RRG5XCK7"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIBRARIES AND DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ],
      "metadata": {
        "id": "n9I8VhyfaBr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "6xlT0WUMZ-62"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES:\n",
        "import transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "NOL1UW_vaWtG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Language Processing**\n",
        "- **NLP** is a field of linguistics and machine learning focused on understanding everything related to human language. The aim of **NLP** tasks is not only to understand single words individually, but to be able to understand the context of those words. "
      ],
      "metadata": {
        "id": "CECqmYGOawxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTIMENT ANALYSIS:**"
      ],
      "metadata": {
        "id": "RkznUFUOcY3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF SENTIMENT ANALYSIS PIPELINE:\n",
        "classifier = pipeline(\"sentiment-analysis\")                                 # Initializing Classifier Object. \n",
        "classifier(\"I've started the HuggingFace course which fascinates me.\")      # Inspecting Sentiment. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibYIi6HBatZn",
        "outputId": "5f625ecb-e772-446e-c7d4-a24c0ca5dff2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997233748435974}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF SENTIMENT ANALYSIS PIPELINE: MULTIPLE:\n",
        "classifier([\"I've started the HuggingFace course which fascinates me.\",\n",
        "            \"I will no longer read it's documentation.\",\n",
        "            \"I think the course is awesome!\"])                              # Inspecting Sentiment. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYpdpAjXc4dH",
        "outputId": "c73aa6d2-e50a-4e79-a94a-1769796f51b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997233748435974},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994686245918274},\n",
              " {'label': 'POSITIVE', 'score': 0.9998465776443481}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipelines**\n",
        "- The three main steps involved when we pass some text to a `pipeline` are: \n",
        "    - The text is preprocessed into a format the model can understand.\n",
        "    - The preprocessed inputs are passed to the model. \n",
        "    - The predictions of the model are post-processed, so we can make sense of them. "
      ],
      "metadata": {
        "id": "bp4Yx3MffEw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZERO-SHOT CLASSIFICATION:**\n",
        "- The `zero-shot-classification` pipeline is very powerful, as it allows us to specify which labels to use for the classification, so we don't have to rely on the labels of the pretrained model. This `pipeline` is called `zero-shot` because we don't need to fine-tune the model on our data to use it. It can directly return probability scores for any list of labels we want. "
      ],
      "metadata": {
        "id": "natPtwAFgD9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF ZERO SHOT CLASSIFICATION PIPELINE: \n",
        "classifier = pipeline(\"zero-shot-classification\")                           # Initializing Classifier Object. \n",
        "classifier(\"This is a course about Transformers library\", \n",
        "           candidate_labels=[\"education\", \"health\", \"computer science\"])    # Inspecting Classification. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt8ilH9VeW1A",
        "outputId": "7597c581-0f53-4d0d-fcf7-b4b2af8c5a59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['education', 'health', 'computer science'],\n",
              " 'scores': [0.7526783347129822, 0.1297907829284668, 0.117530956864357],\n",
              " 'sequence': 'This is a course about Transformers library'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GS1r-kAQirUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}