{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PipelineFunction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ],
      "metadata": {
        "id": "uD9wr0Cmweq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fSALgkZsJCHw"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIBRARIES AND DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ],
      "metadata": {
        "id": "1OnmQkSVwp9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "e6bx-9iQwni7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES:\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "JTf0fK0Kwu3R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTIMENT ANALYSIS:**"
      ],
      "metadata": {
        "id": "kkJil872w4m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF SENTIMENT ANALYSIS PIPELINE:\n",
        "classifier = pipeline(\"sentiment-analysis\")                                 # Initializing Classifier Object. \n",
        "classifier(\"I've started the HuggingFace course which fascinates me.\")      # Inspecting Sentiment."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_SApdSEwzdC",
        "outputId": "17d6c32f-b6ba-4c2e-fcc8-ca0d580c16ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997233748435974}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING WITH TOKENIZER:**\n",
        "- The **tokenizer** will be responsible for: \n",
        "    - Splitting the input into words, subwords, or symbols like puncutation that are also called tokens. \n",
        "    - Mapping each token to an integer. \n",
        "    - Adding additional inputs that may be useful to the model. "
      ],
      "metadata": {
        "id": "mB8yznK7xeV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INITIALIZATION OF AUTOTOKENIZER: \n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"                  # Initialization. \n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)                           # Initializing Tokenizer. "
      ],
      "metadata": {
        "id": "Jw48OV8fxNsC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CONVERTING INTO TENSORS:\n",
        "raw_inputs = [\"I've started the HuggingFace course which fascinates me.\",\n",
        "              \"I will no longer read it's documentation.\",\n",
        "              \"I think the course is awesome!\"]                                 # Initializing Input Text. \n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True,                   # Converting into Equal Size. \n",
        "                   return_tensors=\"pt\")                                         # Getting PyTorch Tensors. \n",
        "print(inputs)                                                                   # Inspecting Tensors with Attention Mask. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QRTHuWPzejE",
        "outputId": "40fbd083-be03-4771-ee79-6a827846a0ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2318,  1996, 17662, 12172,  2607,  2029,\n",
            "          6904, 11020, 28184,  2033,  1012,   102],\n",
            "        [  101,  1045,  2097,  2053,  2936,  3191,  2009,  1005,  1055, 12653,\n",
            "          1012,   102,     0,     0,     0,     0],\n",
            "        [  101,  1045,  2228,  1996,  2607,  2003, 12476,   999,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOING THROUGH MODEL:**\n",
        "- The vector output by the Transformer module is usually large. It generally has 3 dimensions:\n",
        "    - **Batch size:** The number of sequences processed at a time. \n",
        "    - **Sequence length:** The length of the numerical representation of the sequence. \n",
        "    - **Hidden size:** The vector dimension of each model input. "
      ],
      "metadata": {
        "id": "EhHtxFMu07O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INITIALIZATION OF TRANSFORMER MODEL:\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"                  # Initialization. \n",
        "model = AutoModel.from_pretrained(checkpoint)                                   # Initializing Model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBziV4RZ0tYn",
        "outputId": "9da736bf-80bb-4bff-d286-be99fe05b474"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTING VECTOR DIMENSIONS:\n",
        "output = model(**inputs)                                                        # Initializing Output. \n",
        "print(output.last_hidden_state.shape)                                           # Inspecting Shape. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0DF1xLD1idI",
        "outputId": "28558a2c-8725-436e-870f-b41f553bcade"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INITIALIZATION OF SEQUENCE CLASSIFICATION TRANSFORMER MODEL:\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"                  # Initialization. \n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)          # Initializing Model.\n",
        "output = model(**inputs)                                                        # Initializing Output. \n",
        "print(output.logits.shape)                                                      # Inspecting Shape.  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgx0wBTG3rC2",
        "outputId": "dc8fa02b-9cb9-4358-daf3-dddcac135f45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POSTPROCESSING THE OUTPUT:**"
      ],
      "metadata": {
        "id": "0Vpcn_cP5ZNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTING THE OUTPUT:\n",
        "print(output.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcy0rRU5Hkf",
        "outputId": "785a4d1f-18e2-49ad-a275-1da1a0c11dd1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.9449,  4.2477],\n",
            "        [ 4.1948, -3.3446],\n",
            "        [-4.2149,  4.5673]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CONVERTING LOGITS INTO PROBABILITIES:\n",
        "predictions = torch.nn.functional.softmax(output.logits, dim=-1)                # Applying Softmax Function. \n",
        "print(predictions)                                                              # Inspecting Prediction Probabilities. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M1iZ3Xa5jMn",
        "outputId": "7e897944-2bdc-481b-b95f-224008263ef8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.7661e-04, 9.9972e-01],\n",
            "        [9.9947e-01, 5.3144e-04],\n",
            "        [1.5341e-04, 9.9985e-01]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTING MODEL ATTRIBUTE:\n",
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UFDFhhl6VPX",
        "outputId": "8ff92bfd-8d06-411a-f2fa-64483f003353"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}